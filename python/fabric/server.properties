# Fabric ElasticSearch Configuration
server.archive.es.host.ip=fab-emea01-essmas-h5,fab-emea01-essmas-h6,fab-emea01-essmas-h7,fab-emea01-ess-h4-1,fab-emea01-ess-h5-1,fab-emea01-ess-h6-1,fab-emea01-ess-h7-1
server.archive.es.host.tcp.port=9740
server.archive.es.host.port=9640
es.settings.archive.name=actiance-Alcatraz
es.settings.archive.cluster.name=emea01essdata
es.settings.archive.number_of_replicas=1
es.settings.archive.searchguard.ssl.transport.keystore_filepath=/etc/ssl/node-0-keystore.jks
es.settings.archive.searchguard.ssl.transport.keystore_password=changeit
es.settings.archive.searchguard.ssl.transport.truststore_filepath=/etc/ssl/truststore.jks
es.settings.archive.searchguard.ssl.transport.truststore_password=changeit
es.settings.archive.searchguard.ssl.transport.enforce_hostname_verification=false
es.settings.archive.path.home=.

#Fabric Metrics ElasticSearch Configuration
server.metrics.es.host.ip=fab-emea01-essrmas-h5,fab-emea01-essrmas-h6,fab-emea01-essrmas-h7,fab-emea01-essr-h4,fab-emea01-essr-h5,fab-emea01-essr-h6,fab-emea01-essr-h7
server.metrics.es.host.tcp.port=9740
server.metrics.es.host.port=9640
es.settings.metrics.name=actiance-Alcatraz
es.settings.metrics.cluster.name=emea01essreport
es.settings.metrics.number_of_replicas=1
es.settings.metrics.searchguard.ssl.transport.keystore_filepath=/etc/ssl/node-0-keystore.jks
es.settings.metrics.searchguard.ssl.transport.keystore_password=changeit
es.settings.metrics.searchguard.ssl.transport.truststore_filepath=/etc/ssl/truststore.jks
es.settings.metrics.searchguard.ssl.transport.truststore_password=changeit
es.settings.metrics.searchguard.ssl.transport.enforce_hostname_verification=false
es.settings.metrics.path.home=.
#Elastic search SSL required
es.settings.ssl.enabled=true

#Report Properties
report.kibana.version=4.6.2
report.kibana.buildNum=10148
report.port=443
report.http_protocol=https
report.domain.name=report

alcatraz.index.timeout.seconds=120
alcatraz.index.bulk.latch.wait.time=120
alcatraz.index.bulk.size.mb=100
alcatraz.index.bulk.thread.count=5
alcatraz.index.bulk.action.count=1000

#INDEX MANAGER
indexmanager.schemaVersion=3
indexmanager.lock.timeout=5
indexmanager.max.shards=10
indexmanager.min.shards=2
indexmanager.localcache.ttl=25

#INDEX SIZE CALCULATION JOB
alcatraz.shard.maxsizeBytes=21474836480
alcatraz.shard.create.percentageLimit=80
#==========================================================================================
# Ensembles configuration
# ----------
#	Ensembles are virtualized collections of nodes ( server farms ) 
#	that make up a cluster.


# Fabric Rados Gateway
server.primary.object.store.provider=swift
server.primary.object.store.identity=sysops:swift
server.primary.object.store.credential=uLMcR2juy9taQP8LskLipUMoL6D3A80fhnWwvGvH
server.primary.object.store.host.url=http://fab-emea01-cephrad-h1:7480/auth/
server.primary.object.store.metadata.name.seperator=-
blobstore.max.parallel.connection=20
jclouds.max-connections-per-context=20
jclouds.max-connections-per-host=20

# Mongo Authentication
server.mongo.auth.enabled=true
server.primary.mongo.auth.password=pr8d8CSVJI1yRPlSk1GHxA==
server.dr.mongo.auth.password=pr8d8CSVJI1yRPlSk1GHxA==
server.local.mongo.auth.password=pr8d8CSVJI1yRPlSk1GHxA==

# Fabric MongoDb Configuration
## Set to true if mongo is setup as a cluster
mongo.in.cluster.mode=true
## Allow mongo preference settings (If true, collection level preferences will be read, else defaults will be taken)
mongo.allow.preference=false
## MongoDB write concerns. Following are supported values. 
## 1 - W1           (Returns once it sends the data to primary)
## 2 - W2           (Returns once it sends the data to 1 secondary)
## 3 - W3           (Returns once it sends the data to atleast 2 secondaries)
## 4 - Acknowledged (Returns once acknowledgement is received from one mongo node)
## 5 - Journaled    (Returns once it sends the data to Mongod and written in Journal file)
## 6 - Majority     (Returns once it sends the data to atleast 2 secondaries)
##mongo.<collection-name>.write.concern=2
## MongoDB read preference.
## 1 - Primary
## 2 - PrimaryPreferred
## 3 - Secondary
## 4 - SecondaryPreferred
## 5 - Nearest
##mongo.<collection-name>.read.preference=1
## MongoDB read concern
## 1 - local
## 2 - majority
##mongo.<collection-name>.read.concern=1

server.primary.mongo.host.ip=127.0.0.1
server.primary.mongo.host.port=23757
server.primary.mongo.host.maxconnection=100
server.primary.mongo.ssl.enabled=true
server.primary.mongo.ssl.allowinvalidhostnames=true

# Set dr Mongo connection properties. These are not required on primary site.
server.dr.mongo.host.ip=127.0.0.1
server.dr.mongo.host.port=23758
server.dr.mongo.host.maxconnection=100
server.dr.mongo.ssl.enabled=true
server.dr.mongo.ssl.allowinvalidhostnames=true

# Set primary Mongo connection properties in primary site. 
# Set dr Mongo connection properties in dr site.	
server.local.mongo.host.ip=127.0.0.1
server.local.mongo.host.port=23757
server.local.mongo.host.maxconnection=100
server.local.mongo.ssl.enabled=true
server.local.mongo.ssl.allowinvalidhostnames=true

#Session Timeout - This value should be > 300
alcatraz.A3CSessionCache.idle.seconds=3600

#Fabric Hazelcast Configuration
alcatraz.hazelcast.hosts=fab-emea01-haz-h1:5281,fab-emea01-haz-h2:5281,fab-emea01-haz-h3:5281
alcatraz.cache.timeout = 10
alcatraz.hazelcast.mode=true
alcatraz.hazelcast.async.get=false
alcatraz.hazelcast.async.timeout=30

#Fabric KeyManager Configuration
server.keystore.filepath=/apps/config/keystore/admin_one_keystore.jks
server.truststore.filepath=/apps/config/keystore/CATrustStore.jks
server.clientkeystore.filepath=/apps/config/keystore/client_actiance_cert_keystore.jks
server.keystore.password=actiance
server.truststore.password=actiance
server.ip=fab-emea01-twn-h2
server.clientport=6000
server.port=6001
server.username=alcatraz
server.groupname=alcatrazgroup

bootstrap.replay.interval.hours=24
bootstrap.parallel.tenants=5

# Common Configuration
apc.portola.domain.name=jpmc.actiance.net
apc.alcatraz.domain.name=dig.jpmc.actiance.net

#Email Server Configuration
mail.smtp.host=fab-emea01-rh1-h1 
mail.smtp.port=25 
mail.smtp.user.id=
mail.smtp.tls.enabled=false
mail.smtp.auth.reqd=
mail.fromemailaddress=no-reply@actiance.com
mail.nocemailaddress=

#Email Content
email.mailbody = Hi ${FIRSTNAME} ${LASTNAME} ,<br><br>Please click the below link to login to ${BRANDNAME} with following account info: <br><br> ${URL}  <br><br> User Name: ${EMAIL} <br> Pass: <img src=\"${PWDIMAGENAME}\"/> </b><br><br> - ${BRANDNAME} Admin
email.mailsubject = User Credential Details
email.brandname=Alcatraz
sso.email.mailbody = Hi ${FIRSTNAME} ${LASTNAME} ,<br><br>Please click the below link to access ${BRANDNAME}. <br><br> ${URL}  </b><br><br> - ${BRANDNAME} Admin
sso.email.mailsubject = Alcatraz Access Details

#Temp file download path
prop.temp.file.path=/data1/tmp
prop.temp.file.path.tika=/data1/tmp/tika

#Fabric NFS Configuration
nfs.failed.xml.path=/nfs-path/failedxml

#DIG
max.ingest.payload.size=1048576000
payload.stream.buf.size=200000

#Max value that can be set to the below propert is 1GB. Do not set the value to more than 1GB until fix for AP-1914 is available
export.output.chunk.size.bytes=1073741824

#Hit Highlight config
highlight.tokenizer=standard_actiance


#DR common configuration
dr.site.enabled=true
site.type.dr=false
server.dr.host=dr.alcatraz.com
server.dr.request.port=8443
server.dr.listening.port=8443
dr.ceph.url=cxf/actiance/apc/dr/drceph/processEvents
dr.provision.url=cxf/actiance/apc/dr/drceph/provisionTenant
client.dr.ssl.keyStore=/apps/karaf/etc/security/DRClientCert
client.dr.ssl.keyStorePassword=pT8mKROjFWQvUF0LXaaQSw==
alcatraz.site.id=1

#DR topics
primary.seq.events.topic=drSeqPrimary
ceph.pri.bootstrap.topic=cephboot
primary.priority.events.topic=drPriPrimary
primary.events.topics=drSeqPrimary,drPriPrimary
secondary.seq.events.topic=drSeqSecondary
ceph.sec.bootstrap.topic=cephbootsec
secondary.priority.events.topic=drPriSecondary
secondary.events.topics=drSeqSecondary,drPriSecondary

#Email gateway configuration
server.journaling.url=https://vip-jpemea01-egw01:8443/tenantConfig/tenantInsert

#Disposition configuration
#run purge pipeline only during non-peak hours
purge.enabled=true
purge.run.nonpeak.hours=false
#define the non-peak hours window in timezone GMT.
purge.nonpeak.hours=20-6
#for now, assume PDT is for all tenants. 
purge.schedule.frequency=3
#Time in GMT timezone at which purge even publishing should start.
#It is relevant only in case purge.schedule.timeunit property is set to "days"
purge.schedule.start.timeOfDay=12:00 AM
#possible values: minutes, hours, days
purge.schedule.timeunit=minutes
purge.tenantlevel.concurrency=1
purge.policylevel.concurrency=1
purge.daybucketlevel.concurrency=1
purge.event.publish.batch.size=100
#Comma-separated list of Tenant IDs for which purge will not trigger.If this property is specified then 'purge.included.tenant.ids' MUST NOT be specified.
#purge.excluded.tenant.ids="" 
#If specified, purge will trigger ONLY for the comma-separated list of specific Tenant IDs.If this property is specified then 'purge.excluded.tenant.ids' MUST NOT be specified.
#purge.included.tenant.ids=""

#Quick search properties
quicksearch.facet.participant.shard.size = 100
quicksearch.facet.participant.total.size = 10
quicksearch.facet.all.total.size = 50
quicksearch.facet.participants.top.count = 10
quicksearch.scan.search.scrolltime.milliseconds = 60000

#distributed job scheduling properties
master.scheduler.frequency=1
#valid values are minute, second. If no value is specified, default will be minute.
master.scheduler.frequency.timeunit=minute
distributed.job.scheduling.enabled=true
jobs.topic=jobs
#large.holdtag.topic=largeHoldTagTopic
#medium.holdtag.topic=mediumHoldTagTopic
#small.holdtag.topic=smallHoldTagTopic

preview.timeout.seconds=10

#supervision tenants
permission.supervision.tab=devtest06

#only for developer machines
rawstore.enable=true

#Developer properties. No significance in other environments
export.package.location=
export.monitor.zkservers=fab-emea01-kafzoo-h1:2471,fab-emea01-kafzoo-h2:2471,fab-emea01-kafzoo-h3
nfs.path=/nfs-path/stormexports

#reference based messaging
enable.file.based.messaging=true
file.based.messaging.min.size.bytes=1000000
nfs.ingestion.input.path=input

disabled.invalid.es.query.email.body=<b>Dear ${QUEUECREATOR},</b><br><br>This is to inform you that a Supervision Policy ("${QUERYNAME}") associated with the Queue ("${QUEUENAME}") has been disabled by Alcatraz because the advance search query string have some special characters in it.<br><br>It is recommended that you login to Alcatraz to fine tune this policy ${QUERYNAME} <br><br><b>Note:</b> Once you have adjusted the policy parameters, you'll have to manually enable the policy again in the queue. You can do so by clicking on the check box next to this policy name <br> in the queue "${QUEUENAME}" configuration page.<br><br><b>Sincerely,<br>Alcatraz Admin</b>

#supervision notification
supervision.notification=/data1/notification

#supervision notification from
supervision.notification.from=no-reply@actiance.com

#Partner REST APIs
rest.api.mac.enabled=false
apc.alcatraz.api.domain.name=alcatraz.com

#SSO
sso.keystore.path=/apps/karaf/etc/security/.ssokeystore
sso.keystore.password=pT8mKROjFWQvUF0LXaaQSw==
sso.keystore.req.sign.cert.alias=ssoreqcert

#Search functionality
filter.stop.words=true

#ingestion logs count
admin.ingestion.logs.download.limit=50000


#LFS
ingestion.large-file-event.min.size=10000000
ingestion.large-file.chunk.size=5000000
ingestion.max.main.size=20000000
#property value based on which supervision/hold queue will be decided
metadata.doc.count.small.topic=1
metadata.doc.count.medium.topic=50
metadata.doc.count.large.topic=5000
#topics for all hold/unhold action
hold.small.topic=smallHoldTagTopic
hold.medium.topic=mediumHoldTagTopic
hold.large.topic=largeHoldTagTopic
#topic for all supervision actions
supervision.small.topic=supervisionSmalTopic
supervision.medium.topic=supervisionMediumTopic
supervision.large.topic=supervisionLargeTopic

participant.id.name.userattr.resync.interval.secs=14400
supervision.query.id.name.resync.interval.secs=14400
supervision.queue.id.name.resync.interval.secs=14400
config.store.id.name.resync.interval.secs=14400
role.id.name.resync.interval.secs=14400

